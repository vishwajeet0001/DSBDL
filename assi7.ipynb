{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35680bb9-9eb0-40b3-bca3-df14684659fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a9a375-f49f-44f2-9e42-3fa440a3875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('doc1.txt','r') as file:\n",
    "    doc1=file.read()\n",
    "with open('doc2.txt','r')as file:\n",
    "    doc2=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1ac640-6d73-4da6-b9dd-4fc31f65ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is Vishwajeet and running is good for health', 'historical acts']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[doc1,doc2]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a47efc24-15e6-4a21-82e1-6aaec76e9e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Vishwajeet', 'and', 'running', 'is', 'good', 'for', 'health']\n"
     ]
    }
   ],
   "source": [
    "#1tokenization= splitting each words\n",
    "from nltk import word_tokenize\n",
    "t=word_tokenize(doc1)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41187f0d-2a85-421b-aa8f-435baaa10633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Vishwajeet', 'NNP'), ('and', 'CC'), ('running', 'NN'), ('is', 'VBZ'), ('good', 'JJ'), ('for', 'IN'), ('health', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#2POS=Part of Speech (POS) tagging is the process of labeling each word in a sentence with its corresponding part of speech, such as noun, verb, adjective, adverb, etc.\n",
    "from nltk import pos_tag\n",
    "print(pos_tag(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66940551-ab77-4837-a08b-661c3d332fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'Vishwajeet', 'running', 'good', 'health']\n"
     ]
    }
   ],
   "source": [
    "#3 stop word removal-> the,is,and,of\n",
    "from nltk.corpus import stopwords\n",
    "s=set(stopwords.words('english'))\n",
    "c=[]\n",
    "for i in t:\n",
    "    if i not in s:\n",
    "        c.append(i)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56482f8-06ea-4947-a862-9c036bb5746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'vishwajeet', 'run', 'good', 'health']\n"
     ]
    }
   ],
   "source": [
    "#4 stemming->Stemming is the process of reducing words to their root or base form-> running ko run kr diya\n",
    "from nltk.stem import PorterStemmer\n",
    "st=[]\n",
    "for i in c:\n",
    "    j=PorterStemmer().stem(i)\n",
    "    st.append(j)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664b1a93-e787-4b29-ae7c-76180b00d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'Vishwajeet', 'running', 'good', 'health']\n"
     ]
    }
   ],
   "source": [
    "#5 lemmatization->Lemmatization is the process of reducing words to their base or dictionary form ->gives meaningful data\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "l=[]\n",
    "for i in c:\n",
    "    j=WordNetLemmatizer().lemmatize(i)\n",
    "    l.append(j)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d3c8e8-1913-4215-8178-cd0470de307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: \n",
      "        acts       and       for      good    health  historical       is  \\\n",
      "0  0.000000  0.288675  0.288675  0.288675  0.288675    0.000000  0.57735   \n",
      "1  0.707107  0.000000  0.000000  0.000000  0.000000    0.707107  0.00000   \n",
      "\n",
      "         my      name   running  vishwajeet  \n",
      "0  0.288675  0.288675  0.288675    0.288675  \n",
      "1  0.000000  0.000000  0.000000    0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "t=TfidfVectorizer(use_idf=False)\n",
    "tf = pd.DataFrame(t.fit_transform(docs).toarray(),  columns=t.get_feature_names_out())\n",
    "print(\"TF: \\n\",tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9317a3f6-8ad1-4d19-8231-99f8bb5d9715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: \n",
      "        acts       and       for      good    health  historical       is  \\\n",
      "0  0.000000  0.288675  0.288675  0.288675  0.288675    0.000000  0.57735   \n",
      "1  0.707107  0.000000  0.000000  0.000000  0.000000    0.707107  0.00000   \n",
      "\n",
      "         my      name   running  vishwajeet  \n",
      "0  0.288675  0.288675  0.288675    0.288675  \n",
      "1  0.000000  0.000000  0.000000    0.000000  \n"
     ]
    }
   ],
   "source": [
    "id=TfidfVectorizer(use_idf=False,smooth_idf=True)\n",
    "ID = pd.DataFrame(id.fit_transform(docs).toarray(),  columns=id.get_feature_names_out())\n",
    "print(\"TF: \\n\",ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db11ad-623c-41e2-ac03-6e9807e8d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency (TF): This measures the frequency of a term within a document. \n",
    "#It is calculated as the number of times a term appears in a document divided by the total number of terms in the document. \n",
    "#TF gives us an idea of how important a term is to a specific document\n",
    "\n",
    "#This measures the importance of a term across a collection of documents. \n",
    "#It is calculated as the logarithm of the total number of documents divided by the number of documents containing the term"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
