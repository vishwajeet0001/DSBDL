{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6ce6dc-ec05-42cc-b1e9-1ab703cfc995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad72861-b977-47e3-a70c-1123670b6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Real madrid is set to win the UCL for the season . Benzema might win Balon dor . Salah might be the runner up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63268bed-9f31-4b7b-b106-107e075ed6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Real', 'madrid', 'is', 'set', 'to', 'win', 'the', 'UCL', 'for', 'the', 'season', '.', 'Benzema', 'might', 'win', 'Balon', 'dor', '.', 'Salah', 'might', 'be', 'the', 'runner', 'up']\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e11c5ca-868d-4f49-9024-a6d05a6dd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Real', 'JJ'), ('madrid', 'NN'), ('is', 'VBZ'), ('set', 'VBN'), ('to', 'TO'), ('win', 'VB'), ('the', 'DT'), ('UCL', 'NNP'), ('for', 'IN'), ('the', 'DT'), ('season', 'NN'), ('.', '.'), ('Benzema', 'NNP'), ('might', 'MD'), ('win', 'VB'), ('Balon', 'NNP'), ('dor', 'NN'), ('.', '.'), ('Salah', 'NNP'), ('might', 'MD'), ('be', 'VB'), ('the', 'DT'), ('runner', 'NN'), ('up', 'RP')]\n"
     ]
    }
   ],
   "source": [
    "#POS_TAGS\n",
    "from nltk import pos_tag\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c734b0d-f6c0-47ff-9dfa-3ae47575f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Real', 'madrid', 'set', 'win', 'UCL', 'season', '.', 'Benzema', 'might', 'win', 'Balon', 'dor', '.', 'Salah', 'might', 'runner']\n"
     ]
    }
   ],
   "source": [
    "# Stop words removal\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92fa673-f868-4a95-8685-fdcfb7024ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real', 'madrid', 'set', 'win', 'ucl', 'season', '.', 'benzema', 'might', 'win', 'balon', 'dor', '.', 'salah', 'might', 'runner']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "porter = PorterStemmer()\n",
    "stemmed_tokens = [porter.stem(token) for token in filtered_tokens]\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60171a98-adc4-4870-813a-ef110d126ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Real', 'madrid', 'set', 'win', 'UCL', 'season', '.', 'Benzema', 'might', 'win', 'Balon', 'dor', '.', 'Salah', 'might', 'runner']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d66a6f23-ffd7-479f-87cb-9f605f3c9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.17677669529663687\n",
      "  (0, 9)\t0.17677669529663687\n",
      "  (0, 1)\t0.17677669529663687\n",
      "  (0, 10)\t0.17677669529663687\n",
      "  (0, 3)\t0.17677669529663687\n",
      "  (0, 0)\t0.17677669529663687\n",
      "  (0, 7)\t0.35355339059327373\n",
      "  (0, 2)\t0.17677669529663687\n",
      "  (0, 11)\t0.17677669529663687\n",
      "  (0, 4)\t0.17677669529663687\n",
      "  (0, 15)\t0.17677669529663687\n",
      "  (0, 13)\t0.5303300858899106\n",
      "  (0, 17)\t0.35355339059327373\n",
      "  (0, 14)\t0.17677669529663687\n",
      "  (0, 12)\t0.17677669529663687\n",
      "  (0, 5)\t0.17677669529663687\n",
      "  (0, 6)\t0.17677669529663687\n",
      "  (0, 8)\t0.17677669529663687\n"
     ]
    }
   ],
   "source": [
    "#Creating representation of document using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text])\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793c51f-e5f2-42cd-9891-b647b2b3215b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
